{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d892353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3bcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_id = \"9606_0:004caa\"\n",
    "k = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6827e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict = {\n",
    "    \"9606_0:004caa\":\"FAEAWKAQFPDSEPPRMELRSVGDIEQELERCKASIRRLEQEVNQERFRMIYLQTLLAKEKKSYDRQRWGFRRAAQAPDGASEPRASASRPQPAPADGADPPPAEEPEARPDGEGSPGKARPGTARRPGAAASGERDDRGPPASVAALRSNFERIRKGHGQPGADAEKPFYVNVEFHHERGLVKVNDKEVSDRISSLGSQAMQMERKKSQHGAGSSVGDASRPPYRGRSSESSCGVDGDYEDAELNPRFLKDNLIDANGGSRPPWPPLEYQPYQSIYVGGMMEGEGKGPLLRSQSTSEQEKRLTWPRRSYSPRSFEDCGGGYTPDCSSNENLTSSEEDFSSGQSSRVSPSPTTYRMFRDKSRSPSQNSQQSFDSSSPPTPQCHKRHRHCPVVVSEATIVGVRKTGQIWPNDGEGAFHGDADGSFGTPPGYGCAADRAEEQRRHQDGLPYIDDSPSSSPHLSSKGRGSRDALVSGALESTKASE\",\n",
    "    \"7757_0:00087f\":\"FAEAWRAQFPDSEPPKMELRSLRDIEGELCSCKNSIRRLEVEVNKERFRMIYLQTLLAKEKKGYDRQRWGFRKSAQGGGGVAVPGPAGDEAGPDDDGDDPVGEVAAAAAAAAAALGGEMPGGGGGADGERPFPESPSHLRRHAADPDEGFEDTIASSRHRRAKAPDKSPLPPGLVIAPGKGAKGGEPGSPAAAGSPCKSPRVPGPPEPRARRHSSQTSEEAALCGGGGGGSRGSPGADKSSSPLQQQQQLLPPSYANVEFHAERGLVRLNEREVSDHISSLGSEAMRMERRRGGCGTASREPCVSPGRDPPQLRGPSGPGVSASSSSSSGRHHHHHHHQAASHVGYEADYEDAEPPGRFFAASPKQHPKRERPPWHVAEEATGLPESTALTDGDSTYGTGSREQLYPSSGRRQPGTGVPGLGGPPGGGGGGAGFVACKEERLSWPKQQRAHSPSSLEDAGGGYTPDCSSNDNLTSSEDELSSPGGRSGRGGGGGVGGGGAGGGVGMGLAGTGASASPTAGSSSYRLFRERENRSPSQNSQHSLDSSSPPTPHGHGTPAGLGGSGGGGGGGGRRAVRGKPSGGPGAKAVTPPGGGPDSPQRSPAGLGPKRGPPTRSRYGAPDDVFDSYPGESPFGVPSPGYVYDAERGDDGRPPPEGMPYIDDSPSSSPHAAARIRGARDAAAAAAATSAAALDAGKMGE\",\n",
    "    \"42100_0:0032b1\":\"FAEAWKAQFPDSEPPRMELRSVGDIEQELDRCKASIRRLEQEVNQERFRMIYLQTLLAKEKKSYDRQRWGFRRAAQPPDGAAEPRAPRPQPAPADCSDPPPADEPEARLDGEGSPGKARPAATRRPGAAAPADHDDRGPPTSVAALRSNFERIRKGPVQPAATDAEKPFYVNVEFHHERGLVKVNDKDVSDRISSLGSQAMQMERKKSQQGAGPGPGDPPRPSYRGRLSESSCGLDGDFEDAELNPRFLKDNLINANGGSRPPWPPLEYQPYQSIYVGGMMVEGEGKGSLQRSQSTSEQEKRLTWPRRSYSPRSFEDSGGGYTPDCSSNENLTSSEEDFSSGQSSRVSPSPTTYRTFRDKSRSPSQNSQQSFDSSSPPTPQCQKRHRQGPVVVSEATIVGVRKTGQIWPSDGDSLSSRLLQDGAFHGDADAPFGTPPGYGCATDRAEEQRRHQDGLPYMDDSPSSSPHLGSKGRGSRDAPESTKVSE\",\n",
    "    \"8255_0:002868\":\"FVEAWRAQFPESDPPCMELNSLGDIEQELDRCKTSIRQLEKEVNKERFRMIYLQTLLAKERKSYDGQRWGFRRVPQTRDGDQTSEPDSQRSYAGDAPVEEQQPQQQQQQRDYVKPARCKQHPEEEMDGASPAKQKGGVSLVGQDSENPEFPVGTGSVAALRSNFERIRRANSHTAGDGRGLSTMGGQEKPFYVNMEYHHERGLVKVNDRDVSDKIGTLGCQAMQIERKRSLHSLPGNLSAATGDISKAVQKSTEENCSYNGSCDDPEINPHFLKDSVIQPTGGKSERHPAECQPYTSVYVGGMMADGDTRVIHIRDHSIEEEAHLTWPRHSYSPGSFDDVGGGYTPDCSSNENLTSSEEDFSSGQSSHVSPSPTTYQMYREKSRSPSQHSQQSFESSSPPTPLSQKRLKQQVMVSEASIIGVRKTGLPWRSDGDSTTSSRTSHDNSVQGDLEAPYNETPLTYGYELEHSEEHQPHHDPLSYTGSPSSSPRLRSKSRSSRDTQSSGSLESTLSVE\",\n",
    "    \"215358_0:000d84\":\"FVEAWRAQFPESDPPCMDLNSMGDIEQELDKCKTSIRHLEKEVNKERFRMIYLQTLLAKERKSYDGQRWGFKRTPQMNDGDLPTIPDNQRSHTDETAVEEHPLRGPGKTARCKPHPEGEVDGASPAKQKGGVSPVRQDSEAPDFPLGTGSVAALRSNFERIRRDSSHAAGDGRGSSEKPFYVNVEYHHERGLVKVNDREVSDKISTLGCQAMQMERKRSLHSLPGNLSAAMGDINKAVRRGRSTEGNCSYNGSYDDAEANPHFLKDNVIRSTGGKSERQPAECQPYTSVYVGGMMADGDTRIIHIRDHSIEEDAHLTWPRRSYSPGSFDDVGGGYTPDCSSNENLTSSEEDFSSGQSSHVSPSPTTYQMYREKSRSPSQHSFDSSSPPTPLSQKCLKQRAMVSEASIIRGQIWPSDGDSTTSSRTSHDNSLQGDLEAPYNETPPSYGYDLEHSEEHQPRHDPLSFTGSLESTLSVE\",\n",
    "    \"13616_0:00197d\":\"FERHWRAEFPGEPVPAMQLDSVPAMQEELERCKLNLKRLQQVLAEEKFKVIYLQTALAREKRGYDCGRWEGGGGEGDSCSSSGPTKEEEEGVEAEEVRAPTELEHPQPRPQPQPQPRPRSRPQPRPRTRPEPHKEPSSSDSGPGGLASVPRTKSPHYVNLEFPAWRGTPGEGGAVLSLTAAIHQQLQQPQLLLRPREEQEPELELETERALGNGRRPEGSAQSPSALVSESPGASPEEGEELSPAAPEDTEPEALVAAEEGGDSDHDFEVVDLNEKFVLGHLLLAPCRFLPREDTPEKPLRAGSPHRWLHLIGGKRHRRSRDLDQLEAEGKDGRCSPLPPEEAHFRGAREHLPPWRRKKLLGVPGRDSPGHSSPERGSDCSYNSSDHEDVSSADFSYGADDYDGEGNEEQKVPPEGSETMPYIDESPTMSPQLSARSQGSGDGISPTPPEGLGPVVEAG\",\n",
    "    \"336983_0:0004f6\":\"MEPLSHRGLPRLSWIDTLYSNFSYGTDEYDGEGNEEQKGPPEGSETMPYIDESPTMSPQLSARSQGGGDGVSPTPPEGLAPGVEAG\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984ffa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM_Model:\n",
    "    '''\n",
    "    This is from the Kibby package and slightly modified\n",
    "    '''\n",
    "    # esm1b_t33_650M_UR50S\n",
    "    # esm2_t6_8M_UR50D\n",
    "    # esm2_t12_35M_UR50D\n",
    "    # esm2_t30_150M_UR50D\n",
    "    # esm2_t33_650M_UR50D\n",
    "    # esm2_t36_3B_UR50D\n",
    "\n",
    "    def __init__(self, model_name: str = \"esm2_t33_650M_UR50D\"):\n",
    "        self.load(model_name)\n",
    "\n",
    "    def load(self, model_name):\n",
    "        import esm\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model, alphabet = eval(f\"esm.pretrained.{self.model_name}()\")\n",
    "        self.batch_converter = alphabet.get_batch_converter()\n",
    "        self.model.eval()\n",
    "        self.embed_dim = self.model._modules[\"layers\"][0].embed_dim\n",
    "        self.layers = sum(1 for i in self.model._modules[\"layers\"])\n",
    "\n",
    "    def encode(self, sequence, device=\"cuda\", threads=1):\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.set_num_threads(threads)\n",
    "\n",
    "            batch_labels, batch_strs, batch_tokens = self.batch_converter(\n",
    "                [[\"\", sequence]]\n",
    "            )\n",
    "            batch_tokens = batch_tokens.to(device)\n",
    "            self.model = self.model.to(device)\n",
    "            with torch.no_grad():\n",
    "                results = self.model(\n",
    "                    batch_tokens, repr_layers=[self.layers], return_contacts=False\n",
    "                )\n",
    "                results = results[\"representations\"][self.layers].to(\"cpu\")[0]\n",
    "            return results\n",
    "        except:\n",
    "            if device != \"cpu\":\n",
    "                return self.encode(sequence, device=\"cpu\", threads=threads)\n",
    "            else:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47085427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(tensor1, tensor2):\n",
    "    squared_diff = np.square(tensor1 - tensor2)\n",
    "    sum_squared_diff = np.sum(squared_diff)\n",
    "    distance = np.sqrt(sum_squared_diff)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def make_empty_kmer_ortho_df(positions, ortholog_ids: list[str]):\n",
    "    cols = [\"reference_kmer\"] + ortholog_ids\n",
    "    df = pd.DataFrame(\n",
    "        index=positions,\n",
    "        columns=cols,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_kmer_embeddings(seq: str, tensor, k: int):\n",
    "    \"\"\"Generates kmers and their corresponding embeddings from a sequence and\n",
    "    its tensor\n",
    "    Assumes that the sequence and tensor are of the same length (i.e. no start\n",
    "    and end tokens are included in the tensor)\"\"\"\n",
    "    k2 = k - 1\n",
    "    kmers = []\n",
    "    kmer_tensors = []\n",
    "    for i in range(len(seq) - k2):\n",
    "        kmers.append(seq[i : i + k])\n",
    "        kmer_tensors.append(tensor[i : i + k, :])\n",
    "    return kmers, kmer_tensors\n",
    "\n",
    "\n",
    "def get_embedding_dict(\n",
    "    sequence_dict: dict[str, str], mod: ESM_Model\n",
    "):\n",
    "    '''Returns a dictionary of sequences and their embeddings for each sequence in the input dictionary\n",
    "    \n",
    "    input dict: {seq_id: seq_str}\n",
    "    returned dict: {seq_id: [seq_str, seq_tensor]}\n",
    "    '''\n",
    "    embedding_dict = defaultdict(list)\n",
    "    for seq_id, seq_str in sequence_dict.items():\n",
    "        seq_tensor = mod.encode(seq_str, device=\"cuda\")[1:-1, :] # remove start and end tokens\n",
    "        embedding_dict[seq_id].append(seq_str)\n",
    "        embedding_dict[seq_id].append(seq_tensor)\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "def find_best_ortho_match_embeddings(kmer_tensor, ortho_str, ortho_tensor):\n",
    "    \"\"\"find best match between kmer tensor and an ortholog tensor\n",
    "    Uses a sliding window approach and calculates the euclidean distance between\n",
    "    the `kmer_tensor` and each length k slice of the `ortho_tensor`. Returns the\n",
    "    distance, sequence, and position of the best matching ortholog slice of length k\n",
    "    \n",
    "    Notes: don't need to use the sequence, could just use the returned best position to\n",
    "    slice the sequence later\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmer_tensor : torch.Tensor\n",
    "        kmer tensor slice\n",
    "    ortho_str : str\n",
    "        sequence of the ortholog\n",
    "    ortho_tensor : torch.Tensor\n",
    "        full tensor of the ortholog sequence. Will be sliced to the same length\n",
    "        as the kmer tensor for each position (sliding window approach)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        returns a tuple of the (euclidean distance, sequence, position) of \n",
    "        the best matching ortholog slice of length k\n",
    "    \"\"\"    \n",
    "    pos, dist, seq = [], [], []\n",
    "    for i in range(len(ortho_str) - (len(kmer_tensor) - 1)):\n",
    "        # slice the ortholog tensor to the same length as the kmer tensor\n",
    "        target_tensor = ortho_tensor[i : i + len(kmer_tensor), :]\n",
    "        # calculate the euclidean distance between the kmer tensor and the ortholog slice tensor\n",
    "        dist_i = euclidean_distance(np.array(kmer_tensor), np.array(target_tensor))\n",
    "        pos.append(i)\n",
    "        dist.append(dist_i)\n",
    "        seq.append(ortho_str[i : i + len(kmer_tensor)])\n",
    "    best_match_ind = np.argmin(dist)\n",
    "    return dist[best_match_ind], seq[best_match_ind], pos[best_match_ind]\n",
    "\n",
    "# def find_best_ortho_match_embeddings_v2(kmer_tensor, ortho_str, ortho_tensor):\n",
    "#     best_dist = np.inf\n",
    "#     for i in range(len(ortho_str) - (len(kmer_tensor) - 1)):\n",
    "#         # slice the ortholog tensor to the same length as the kmer tensor\n",
    "#         target_tensor = ortho_tensor[i : i + len(kmer_tensor), :]\n",
    "#         # calculate the euclidean distance between the kmer tensor and the ortholog slice tensor\n",
    "#         dist_i = euclidean_distance(np.array(kmer_tensor), np.array(target_tensor))\n",
    "#         if dist_i < best_dist:\n",
    "#             best_dist = dist_i\n",
    "#             best_pos = i\n",
    "#     return best_dist, ortho_str[best_pos : best_pos + len(kmer_tensor)], best_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398ca4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pairwise_kmer_emb_aln(\n",
    "    reference_id: str,\n",
    "    embedding_dict: dict,\n",
    "    k: int,\n",
    "):\n",
    "    # get the reference sequence and remove it from the embedding_dict\n",
    "    ref_seq_str, ref_seq_embedding = embedding_dict.pop(reference_id)\n",
    "    kmers, kmer_tensors = generate_kmer_embeddings(\n",
    "        seq=ref_seq_str,\n",
    "        tensor=ref_seq_embedding,\n",
    "        k=k,\n",
    "    )\n",
    "    positions = list(range(len(kmers)))\n",
    "    score_df = make_empty_kmer_ortho_df(positions, list(embedding_dict.keys()))\n",
    "    subseq_df = make_empty_kmer_ortho_df(positions, list(embedding_dict.keys()))\n",
    "    pos_df = make_empty_kmer_ortho_df(positions, list(embedding_dict.keys()))\n",
    "    \n",
    "    # for each kmer in the reference sequence\n",
    "    for position, kmer, kmer_tensor in zip(positions, kmers, kmer_tensors):\n",
    "        score_df.loc[position, \"reference_kmer\"] = kmer\n",
    "        subseq_df.loc[position, \"reference_kmer\"] = kmer\n",
    "        pos_df.loc[position, \"reference_kmer\"] = kmer\n",
    "\n",
    "        # for each ortholog sequence\n",
    "        for ortholog_id, v in embedding_dict.items():\n",
    "            ortholog_seq = v[0]\n",
    "            ortholog_embedding = v[1]\n",
    "            if ortholog_seq is None or ortholog_embedding is None:\n",
    "                continue\n",
    "            if len(ortholog_seq) < k:\n",
    "                continue\n",
    "            try:\n",
    "                # find the best match between the kmer tensor and the ortholog tensor\n",
    "                best_score, best_subseq, best_pos = find_best_ortho_match_embeddings(\n",
    "                    kmer_tensor, ortholog_seq, ortholog_embedding\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            score_df.loc[position, ortholog_id] = best_score\n",
    "            subseq_df.loc[position, ortholog_id] = best_subseq\n",
    "            pos_df.loc[position, ortholog_id] = best_pos\n",
    "    return score_df, subseq_df, pos_df\n",
    "\n",
    "\n",
    "def main(\n",
    "    sequence_dict: dict[str, str],\n",
    "    reference_id: str,\n",
    "    k: int,\n",
    "):\n",
    "    mod = ESM_Model()\n",
    "    embedding_dict = get_embedding_dict(sequence_dict, mod)\n",
    "    score_df, subseq_df, pos_df = run_pairwise_kmer_emb_aln(\n",
    "        reference_id,\n",
    "        embedding_dict,\n",
    "        k,\n",
    "    )\n",
    "    return score_df, subseq_df, pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78c1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df, subseq_df, pos_df = main(seq_dict, reference_id, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3f4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_kmer</th>\n",
       "      <th>7757_0:00087f</th>\n",
       "      <th>42100_0:0032b1</th>\n",
       "      <th>8255_0:002868</th>\n",
       "      <th>215358_0:000d84</th>\n",
       "      <th>13616_0:00197d</th>\n",
       "      <th>336983_0:0004f6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAEAWKAQFPDSEP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEAWKAQFPDSEPP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EAWKAQFPDSEPPR</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWKAQFPDSEPPRM</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKAQFPDSEPPRME</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>GSRDALVSGALEST</td>\n",
       "      <td>275</td>\n",
       "      <td>469</td>\n",
       "      <td>496</td>\n",
       "      <td>395</td>\n",
       "      <td>438</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>SRDALVSGALESTK</td>\n",
       "      <td>276</td>\n",
       "      <td>470</td>\n",
       "      <td>497</td>\n",
       "      <td>391</td>\n",
       "      <td>433</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>RDALVSGALESTKA</td>\n",
       "      <td>277</td>\n",
       "      <td>471</td>\n",
       "      <td>498</td>\n",
       "      <td>397</td>\n",
       "      <td>340</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>DALVSGALESTKAS</td>\n",
       "      <td>278</td>\n",
       "      <td>472</td>\n",
       "      <td>499</td>\n",
       "      <td>398</td>\n",
       "      <td>341</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>ALVSGALESTKASE</td>\n",
       "      <td>378</td>\n",
       "      <td>473</td>\n",
       "      <td>500</td>\n",
       "      <td>399</td>\n",
       "      <td>436</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_kmer 7757_0:00087f 42100_0:0032b1 8255_0:002868  \\\n",
       "0    FAEAWKAQFPDSEP             0              0             0   \n",
       "1    AEAWKAQFPDSEPP             1              1             1   \n",
       "2    EAWKAQFPDSEPPR             2              2             2   \n",
       "3    AWKAQFPDSEPPRM             3              3             3   \n",
       "4    WKAQFPDSEPPRME             4              4             4   \n",
       "..              ...           ...            ...           ...   \n",
       "465  GSRDALVSGALEST           275            469           496   \n",
       "466  SRDALVSGALESTK           276            470           497   \n",
       "467  RDALVSGALESTKA           277            471           498   \n",
       "468  DALVSGALESTKAS           278            472           499   \n",
       "469  ALVSGALESTKASE           378            473           500   \n",
       "\n",
       "    215358_0:000d84 13616_0:00197d 336983_0:0004f6  \n",
       "0                 0              0               0  \n",
       "1                 1              1              14  \n",
       "2                 2              2              15  \n",
       "3                 3              3              16  \n",
       "4                 4              4              17  \n",
       "..              ...            ...             ...  \n",
       "465             395            438              59  \n",
       "466             391            433              60  \n",
       "467             397            340              25  \n",
       "468             398            341              26  \n",
       "469             399            436              28  \n",
       "\n",
       "[470 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f65d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "odb_conservation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
